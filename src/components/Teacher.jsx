/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
Command: npx gltfjsx@6.2.3 public/models/Teacher.glb -r public -o src/components/Teacher.jsx
*/

import { teachers, useAITeacher } from "@/hooks/useAITeacher";
import { Html, useAnimations, useGLTF } from "@react-three/drei";
import { useFrame } from "@react-three/fiber";
import { useEffect, useRef, useState } from "react";
import { MathUtils, MeshStandardMaterial } from "three";
import { randInt } from "three/src/math/MathUtils";

const ANIMATION_FADE_TIME = 0.5;

export function Teacher({ teacher, ...props }) {
  const group = useRef();
  const { scene } = useGLTF(`/models/Teacher_${teacher}.glb`);
  useEffect(() => {
    scene.traverse((child) => {
      if (child.material) {
        child.material = new MeshStandardMaterial({
          map: child.material.map,
        });
      }
    });
  }, [scene]);

  // Load animations FIRST
  const { animations } = useGLTF(`/models/animations_${teacher}.glb`);
  // THEN use them
  const { actions, mixer } = useAnimations(animations, group);
  const [animation, setAnimation] = useState("Idle");

  // Read state needed for lip sync AND loading state
  const loading = useAITeacher((state) => state.loading);
  const currentMessageIndex = useAITeacher((state) => state.currentMessage);
  const playingAudio = useAITeacher((state) => state.playingAudio);
  const playingVisemes = useAITeacher((state) => state.playingVisemes);

  // Imported from r3f-virtual-girlfriend project
  const [blink, setBlink] = useState(false);

  useEffect(() => {
    let blinkTimeout;
    const nextBlink = () => {
      blinkTimeout = setTimeout(() => {
        setBlink(true);
        setTimeout(() => {
          setBlink(false);
          nextBlink();
        }, 100);
      }, randInt(1000, 5000));
    };
    nextBlink();
    return () => clearTimeout(blinkTimeout);
  }, []);

  useEffect(() => {
    if (loading) {
      setAnimation("Thinking");
    } else if (currentMessageIndex !== null && playingAudio) {
      // Check if audio is playing for Talking animation
      setAnimation(randInt(0, 1) ? "Talking" : "Talking2");
    } else {
      setAnimation("Idle");
    }
  }, [loading, currentMessageIndex, playingAudio]);

  useFrame(({ camera }) => {
    // Smile
    lerpMorphTarget("mouthSmile", 0.2, 0.5);
    // Blinking
    lerpMorphTarget("eye_close", blink ? 1 : 0, 0.5);

    // Talking / Lip Sync
    for (let i = 0; i <= 21; i++) {
      lerpMorphTarget(i, 0, 0.1); // reset morph targets
    }

    if (
      currentMessageIndex !== null &&
      playingVisemes?.length > 0 &&
      playingAudio
    ) {
      for (let i = playingVisemes.length - 1; i >= 0; i--) {
        const viseme = playingVisemes[i];
        if (playingAudio.currentTime * 1000 >= viseme[0]) {
          lerpMorphTarget(viseme[1], 1, 0.2);
          break;
        }
      }
      if (
        actions[animation] &&
        actions[animation].time >
        actions[animation].getClip().duration - ANIMATION_FADE_TIME
      ) {
        setAnimation((animation) =>
          animation === "Talking" ? "Talking2" : "Talking"
        );
      }
    }
  });

  useEffect(() => {
    actions[animation]
      ?.reset()
      .fadeIn(mixer.time > 0 ? ANIMATION_FADE_TIME : 0)
      .play();
    return () => {
      actions[animation]?.fadeOut(ANIMATION_FADE_TIME);
    };
  }, [animation, actions]);

  const lerpMorphTarget = (target, value, speed = 0.1) => {
    scene.traverse((child) => {
      if (child.isSkinnedMesh && child.morphTargetInfluences) {
        if (target >= 0 && target < child.morphTargetInfluences.length) {
          child.morphTargetInfluences[target] = MathUtils.lerp(
            child.morphTargetInfluences[target],
            value,
            speed
          );
        }
      }
    });
  };

  const [thinkingText, setThinkingText] = useState(".");

  useEffect(() => {
    if (loading) { // Use loading state here as well for the thinking indicator text
      const interval = setInterval(() => {
        setThinkingText((thinkingText) => {
          if (thinkingText.length === 3) {
            return ".";
          }
          return thinkingText + ".";
        });
      }, 500);
      return () => clearInterval(interval);
    }
  }, [loading]); // Use loading dependency

  return (
    <group {...props} dispose={null} ref={group}>
      {loading && ( // Show thinking indicator only when loading
        <Html position-y={teacher === "Nanami" ? 1.6 : 1.8}>
          <div className="flex justify-center items-center -translate-x-1/2">
            <span className="relative flex h-8 w-8 items-center justify-center">
              <span className="animate-ping absolute inline-flex h-full w-full rounded-full bg-white opacity-75"></span>
              <span className="relative inline-flex items-center justify-center duration-75 rounded-full h-8 w-8 bg-white/80">
                {thinkingText}
              </span>
            </span>
          </div>
        </Html>
      )}
      <primitive object={scene} />
    </group>
  );
}

teachers.forEach((teacher) => {
  useGLTF.preload(`/models/Teacher_${teacher}.glb`);
  useGLTF.preload(`/models/animations_${teacher}.glb`);
});
